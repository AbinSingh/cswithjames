{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import pacakes and layer\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_module(input):\n",
    "    #print(input.shape)\n",
    "    \n",
    "    Conv2D_reduce = Conv2D(16, (1,1), strides=(2,2), activation='relu', padding='same')(input)\n",
    "    #print(Conv2D_reduce.shape)\n",
    "    \n",
    "    Conv2D_1_1 = Conv2D(16, (1,1), activation='relu', padding='same')(input)\n",
    "    #print(Conv2D_1_1.shape)\n",
    "    Conv2D_3_3 = Conv2D(16, (3,3),strides=(2,2), activation='relu', padding='same')(Conv2D_1_1)\n",
    "    #print(Conv2D_3_3.shape)\n",
    "    Conv2D_5_5 = Conv2D(16, (5,5),strides=(2,2), activation='relu', padding='same')(Conv2D_1_1)\n",
    "    #print(Conv2D_5_5.shape)\n",
    "    \n",
    "    MaxPool2D_3_3 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(input)\n",
    "    #print(MaxPool2D_3_3.shape)\n",
    "    Cov2D_Pool = Conv2D(16, (1,1), activation='relu', padding='same')(MaxPool2D_3_3)\n",
    "    #print(Cov2D_Pool.shape)\n",
    "    \n",
    "    concat = Concatenate(axis=-1)([Conv2D_reduce,Conv2D_3_3,Conv2D_5_5,Cov2D_Pool])\n",
    "    #print(concat.shape)\n",
    "    \n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GoogLeNet Define, not using the sequential model, becuase googlenet is not sequential\n",
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "\n",
    "Conv2D_1 = Conv2D(64, (3,3), activation='relu', padding='same')(input)\n",
    "MaxPool2D_1 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(Conv2D_1)\n",
    "BatchNorm_1 = BatchNormalization()(MaxPool2D_1)\n",
    "\n",
    "Module_1 = add_module(BatchNorm_1)\n",
    "Module_1 = add_module(Module_1)\n",
    "\n",
    "Output = Flatten()(Module_1)\n",
    "Output = Dense(num_classes, activation='softmax')(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input], outputs=[Output])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 1.4513 - acc: 0.4797 - val_loss: 1.6572 - val_acc: 0.4480\n",
      "Epoch 2/1000\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 1.1005 - acc: 0.6134 - val_loss: 1.0881 - val_acc: 0.6088\n",
      "Epoch 3/1000\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 0.9655 - acc: 0.6629 - val_loss: 1.0270 - val_acc: 0.6395\n",
      "Epoch 4/1000\n",
      "50000/50000 [==============================] - 18s 359us/step - loss: 0.8698 - acc: 0.6969 - val_loss: 1.0682 - val_acc: 0.6285\n",
      "Epoch 5/1000\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.8094 - acc: 0.7172 - val_loss: 1.0474 - val_acc: 0.6492\n",
      "Epoch 6/1000\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 0.7554 - acc: 0.7382 - val_loss: 0.9172 - val_acc: 0.6856\n",
      "Epoch 7/1000\n",
      "50000/50000 [==============================] - 17s 346us/step - loss: 0.7185 - acc: 0.7492 - val_loss: 0.9088 - val_acc: 0.6893\n",
      "Epoch 8/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.6887 - acc: 0.7606 - val_loss: 0.9340 - val_acc: 0.6849\n",
      "Epoch 9/1000\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.6522 - acc: 0.7732 - val_loss: 1.0184 - val_acc: 0.6679\n",
      "Epoch 10/1000\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.6254 - acc: 0.7840 - val_loss: 0.9613 - val_acc: 0.6811\n",
      "Epoch 11/1000\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 0.5985 - acc: 0.7915 - val_loss: 0.9483 - val_acc: 0.6851\n",
      "Epoch 12/1000\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.5783 - acc: 0.7986 - val_loss: 0.9921 - val_acc: 0.6800\n",
      "Epoch 13/1000\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.5560 - acc: 0.8039 - val_loss: 0.9193 - val_acc: 0.7001\n",
      "Epoch 14/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.5419 - acc: 0.8101 - val_loss: 0.9459 - val_acc: 0.7005\n",
      "Epoch 15/1000\n",
      "50000/50000 [==============================] - 14s 279us/step - loss: 0.5226 - acc: 0.8147 - val_loss: 0.9348 - val_acc: 0.7021\n",
      "Epoch 16/1000\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.5010 - acc: 0.8224 - val_loss: 1.0053 - val_acc: 0.6942\n",
      "Epoch 17/1000\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.4871 - acc: 0.8278 - val_loss: 0.9346 - val_acc: 0.7153\n",
      "Epoch 18/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.4704 - acc: 0.8347 - val_loss: 0.9642 - val_acc: 0.7033\n",
      "Epoch 19/1000\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.4570 - acc: 0.8375 - val_loss: 1.0042 - val_acc: 0.6961\n",
      "Epoch 20/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.4450 - acc: 0.8400 - val_loss: 1.0270 - val_acc: 0.7013\n",
      "Epoch 21/1000\n",
      "50000/50000 [==============================] - 17s 346us/step - loss: 0.4293 - acc: 0.8472 - val_loss: 1.1433 - val_acc: 0.6811\n",
      "Epoch 22/1000\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.4232 - acc: 0.8504 - val_loss: 1.0533 - val_acc: 0.6910\n",
      "Epoch 23/1000\n",
      "50000/50000 [==============================] - 17s 346us/step - loss: 0.4144 - acc: 0.8517 - val_loss: 1.0242 - val_acc: 0.7022\n",
      "Epoch 24/1000\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.3959 - acc: 0.8567 - val_loss: 1.0753 - val_acc: 0.6957\n",
      "Epoch 25/1000\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.3899 - acc: 0.8599 - val_loss: 1.1597 - val_acc: 0.6750\n",
      "Epoch 26/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.3782 - acc: 0.8635 - val_loss: 1.1028 - val_acc: 0.7040\n",
      "Epoch 27/1000\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.3712 - acc: 0.8654 - val_loss: 1.0845 - val_acc: 0.6993\n",
      "Epoch 28/1000\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.3673 - acc: 0.8684 - val_loss: 1.1180 - val_acc: 0.6873\n",
      "Epoch 29/1000\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.3530 - acc: 0.8733 - val_loss: 1.3130 - val_acc: 0.6765\n",
      "Epoch 30/1000\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.3469 - acc: 0.8747 - val_loss: 1.2074 - val_acc: 0.6879\n",
      "Epoch 31/1000\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.3374 - acc: 0.8781 - val_loss: 1.1549 - val_acc: 0.6964\n",
      "Epoch 32/1000\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 0.3296 - acc: 0.8814 - val_loss: 1.1898 - val_acc: 0.6985\n",
      "Epoch 33/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.3254 - acc: 0.8820 - val_loss: 1.1915 - val_acc: 0.6896\n",
      "Epoch 34/1000\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.3138 - acc: 0.8864 - val_loss: 1.2944 - val_acc: 0.6807\n",
      "Epoch 35/1000\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.3077 - acc: 0.8897 - val_loss: 1.2595 - val_acc: 0.6987\n",
      "Epoch 36/1000\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 0.2994 - acc: 0.8927 - val_loss: 1.3786 - val_acc: 0.6813\n",
      "Epoch 37/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.2958 - acc: 0.8936 - val_loss: 1.2402 - val_acc: 0.7060\n",
      "Epoch 38/1000\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.2970 - acc: 0.8931 - val_loss: 1.3441 - val_acc: 0.6915\n",
      "Epoch 39/1000\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 0.2864 - acc: 0.8956 - val_loss: 1.3176 - val_acc: 0.6952\n",
      "Epoch 40/1000\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.2885 - acc: 0.8958 - val_loss: 1.3834 - val_acc: 0.6908\n",
      "Epoch 41/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.2712 - acc: 0.9015 - val_loss: 1.4393 - val_acc: 0.6906\n",
      "Epoch 42/1000\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.2653 - acc: 0.9032 - val_loss: 1.4477 - val_acc: 0.6851\n",
      "Epoch 43/1000\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.2622 - acc: 0.9039 - val_loss: 1.3913 - val_acc: 0.7029\n",
      "Epoch 44/1000\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.2683 - acc: 0.9017 - val_loss: 1.4927 - val_acc: 0.6785\n",
      "Epoch 45/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.2548 - acc: 0.9064 - val_loss: 1.6359 - val_acc: 0.6831\n",
      "Epoch 46/1000\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 0.2544 - acc: 0.9057 - val_loss: 1.4803 - val_acc: 0.6872\n",
      "Epoch 47/1000\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.2494 - acc: 0.9081 - val_loss: 1.4879 - val_acc: 0.6891\n",
      "Epoch 48/1000\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.2400 - acc: 0.9113 - val_loss: 1.5489 - val_acc: 0.6859\n",
      "Epoch 49/1000\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.2273 - acc: 0.9167 - val_loss: 1.5485 - val_acc: 0.6985\n",
      "Epoch 50/1000\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.2328 - acc: 0.9142 - val_loss: 1.5659 - val_acc: 0.6880\n",
      "Epoch 51/1000\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.2288 - acc: 0.9149 - val_loss: 1.5620 - val_acc: 0.6968\n",
      "Epoch 52/1000\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.2297 - acc: 0.9157 - val_loss: 1.7017 - val_acc: 0.6830\n",
      "Epoch 53/1000\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 0.2182 - acc: 0.9195 - val_loss: 1.8195 - val_acc: 0.6711\n",
      "Epoch 54/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.2224 - acc: 0.9163 - val_loss: 1.6503 - val_acc: 0.6805\n",
      "Epoch 55/1000\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.2183 - acc: 0.9192 - val_loss: 1.7678 - val_acc: 0.6703\n",
      "Epoch 56/1000\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.2188 - acc: 0.9188 - val_loss: 1.6635 - val_acc: 0.6909\n",
      "Epoch 57/1000\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.2077 - acc: 0.9224 - val_loss: 1.7570 - val_acc: 0.6907\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.2106 - acc: 0.9213 - val_loss: 1.7352 - val_acc: 0.6855\n",
      "Epoch 59/1000\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.2042 - acc: 0.9244 - val_loss: 1.6976 - val_acc: 0.6930\n",
      "Epoch 60/1000\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.2036 - acc: 0.9245 - val_loss: 1.7596 - val_acc: 0.6855\n",
      "Epoch 61/1000\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.1940 - acc: 0.9278 - val_loss: 1.7771 - val_acc: 0.6842\n",
      "Epoch 62/1000\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.1979 - acc: 0.9271 - val_loss: 1.7434 - val_acc: 0.6860\n",
      "Epoch 63/1000\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.1996 - acc: 0.9271 - val_loss: 1.8667 - val_acc: 0.6838\n",
      "Epoch 64/1000\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 0.1883 - acc: 0.9303 - val_loss: 1.8051 - val_acc: 0.6945\n",
      "Epoch 65/1000\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.1860 - acc: 0.9322 - val_loss: 1.8998 - val_acc: 0.6790\n",
      "Epoch 66/1000\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.1887 - acc: 0.9297 - val_loss: 2.0783 - val_acc: 0.6727\n",
      "Epoch 67/1000\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.1799 - acc: 0.9323 - val_loss: 1.8466 - val_acc: 0.6899\n",
      "Epoch 68/1000\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.1800 - acc: 0.9336 - val_loss: 1.9021 - val_acc: 0.6848\n",
      "Epoch 69/1000\n",
      "50000/50000 [==============================] - 17s 346us/step - loss: 0.1879 - acc: 0.9304 - val_loss: 1.9117 - val_acc: 0.6875\n",
      "Epoch 70/1000\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 0.1784 - acc: 0.9335 - val_loss: 1.9503 - val_acc: 0.6836\n",
      "Epoch 71/1000\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.1741 - acc: 0.9366 - val_loss: 1.9440 - val_acc: 0.6910\n",
      "Epoch 72/1000\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.1748 - acc: 0.9345 - val_loss: 2.0694 - val_acc: 0.6742\n",
      "Epoch 73/1000\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 0.1717 - acc: 0.9365 - val_loss: 2.0318 - val_acc: 0.6718\n",
      "Epoch 74/1000\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.1673 - acc: 0.9382 - val_loss: 2.0676 - val_acc: 0.6791\n",
      "Epoch 75/1000\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.1659 - acc: 0.9370 - val_loss: 2.0092 - val_acc: 0.6817\n",
      "Epoch 76/1000\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.1617 - acc: 0.9404 - val_loss: 2.0250 - val_acc: 0.6906\n",
      "Epoch 77/1000\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.1652 - acc: 0.9380 - val_loss: 2.0172 - val_acc: 0.6880\n",
      "Epoch 78/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.1652 - acc: 0.9383 - val_loss: 2.1023 - val_acc: 0.6841\n",
      "Epoch 79/1000\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 0.1686 - acc: 0.9361 - val_loss: 2.1277 - val_acc: 0.6819\n",
      "Epoch 80/1000\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.1560 - acc: 0.9422 - val_loss: 2.3887 - val_acc: 0.6473\n",
      "Epoch 81/1000\n",
      "50000/50000 [==============================] - 17s 346us/step - loss: 0.1524 - acc: 0.9432 - val_loss: 2.0940 - val_acc: 0.6845\n",
      "Epoch 82/1000\n",
      "50000/50000 [==============================] - 16s 323us/step - loss: 0.1582 - acc: 0.9423 - val_loss: 2.1724 - val_acc: 0.6837\n",
      "Epoch 83/1000\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.1635 - acc: 0.9397 - val_loss: 2.1009 - val_acc: 0.6809\n",
      "Epoch 84/1000\n",
      "50000/50000 [==============================] - 18s 350us/step - loss: 0.1572 - acc: 0.9406 - val_loss: 2.0728 - val_acc: 0.6935\n",
      "Epoch 85/1000\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.1539 - acc: 0.9441 - val_loss: 2.1551 - val_acc: 0.6852\n",
      "Epoch 86/1000\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.1544 - acc: 0.9429 - val_loss: 2.1562 - val_acc: 0.6859\n",
      "Epoch 87/1000\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.1444 - acc: 0.9469 - val_loss: 2.3222 - val_acc: 0.6618\n",
      "Epoch 88/1000\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.1425 - acc: 0.9463 - val_loss: 2.1917 - val_acc: 0.6841\n",
      "Epoch 89/1000\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 0.1497 - acc: 0.9435 - val_loss: 2.1525 - val_acc: 0.6815\n",
      "Epoch 90/1000\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.1470 - acc: 0.9456 - val_loss: 2.1889 - val_acc: 0.6829\n",
      "Epoch 91/1000\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.1491 - acc: 0.9449 - val_loss: 2.1848 - val_acc: 0.6829\n",
      "Epoch 92/1000\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 0.1374 - acc: 0.9495 - val_loss: 2.2505 - val_acc: 0.6814\n",
      "Epoch 93/1000\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.1434 - acc: 0.9481 - val_loss: 2.3435 - val_acc: 0.6791\n",
      "Epoch 94/1000\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.1441 - acc: 0.9453 - val_loss: 2.3128 - val_acc: 0.6773\n",
      "Epoch 95/1000\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 0.1407 - acc: 0.9485 - val_loss: 2.2225 - val_acc: 0.6849\n",
      "Epoch 96/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.1459 - acc: 0.9457 - val_loss: 2.3264 - val_acc: 0.6774\n",
      "Epoch 97/1000\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.1404 - acc: 0.9480 - val_loss: 2.4578 - val_acc: 0.6688\n",
      "Epoch 98/1000\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.1311 - acc: 0.9507 - val_loss: 2.3719 - val_acc: 0.6847\n",
      "Epoch 99/1000\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 0.1363 - acc: 0.9498 - val_loss: 2.3724 - val_acc: 0.6799\n",
      "Epoch 100/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.1288 - acc: 0.9514 - val_loss: 2.4182 - val_acc: 0.6720\n",
      "Epoch 101/1000\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.1375 - acc: 0.9494 - val_loss: 2.3752 - val_acc: 0.6825\n",
      "Epoch 102/1000\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.1254 - acc: 0.9536 - val_loss: 2.3542 - val_acc: 0.6753\n",
      "Epoch 103/1000\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 0.1404 - acc: 0.9487 - val_loss: 2.3849 - val_acc: 0.6783\n",
      "Epoch 104/1000\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.1277 - acc: 0.9524 - val_loss: 2.4408 - val_acc: 0.6715\n",
      "Epoch 105/1000\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 0.1220 - acc: 0.9549 - val_loss: 2.4114 - val_acc: 0.6810\n",
      "Epoch 106/1000\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 0.1363 - acc: 0.9508 - val_loss: 2.4163 - val_acc: 0.6751\n",
      "Epoch 107/1000\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.1406 - acc: 0.9481 - val_loss: 2.4789 - val_acc: 0.6708\n",
      "Epoch 108/1000\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.1190 - acc: 0.9560 - val_loss: 2.5025 - val_acc: 0.6768\n",
      "Epoch 109/1000\n",
      "50000/50000 [==============================] - 16s 322us/step - loss: 0.1226 - acc: 0.9541 - val_loss: 2.4824 - val_acc: 0.6786\n",
      "Epoch 110/1000\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 0.1321 - acc: 0.9510 - val_loss: 2.5110 - val_acc: 0.6686\n",
      "Epoch 111/1000\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.1203 - acc: 0.9562 - val_loss: 2.4685 - val_acc: 0.6788\n",
      "Epoch 112/1000\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 0.1264 - acc: 0.9530 - val_loss: 2.4764 - val_acc: 0.6816\n",
      "Epoch 113/1000\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 0.1285 - acc: 0.9531 - val_loss: 2.5169 - val_acc: 0.6751\n",
      "Epoch 114/1000\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.1191 - acc: 0.9563 - val_loss: 2.5257 - val_acc: 0.6792\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.1191 - acc: 0.9567 - val_loss: 2.4625 - val_acc: 0.6833\n",
      "Epoch 116/1000\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.1268 - acc: 0.9532 - val_loss: 2.4506 - val_acc: 0.6827\n",
      "Epoch 117/1000\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.1130 - acc: 0.9586 - val_loss: 2.5225 - val_acc: 0.6746\n",
      "Epoch 118/1000\n",
      "50000/50000 [==============================] - 16s 320us/step - loss: 0.1212 - acc: 0.9554 - val_loss: 2.5399 - val_acc: 0.6788\n",
      "Epoch 119/1000\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.1292 - acc: 0.9527 - val_loss: 2.4882 - val_acc: 0.6817\n",
      "Epoch 120/1000\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.1272 - acc: 0.9541 - val_loss: 2.5972 - val_acc: 0.6745\n",
      "Epoch 121/1000\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.1139 - acc: 0.9575 - val_loss: 2.6997 - val_acc: 0.6622\n",
      "Epoch 122/1000\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.1235 - acc: 0.9542 - val_loss: 2.6162 - val_acc: 0.6724\n",
      "Epoch 123/1000\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.1215 - acc: 0.9558 - val_loss: 2.5791 - val_acc: 0.6754\n",
      "Epoch 124/1000\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.1063 - acc: 0.9617 - val_loss: 2.5726 - val_acc: 0.6802\n",
      "Epoch 125/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.1240 - acc: 0.9556 - val_loss: 2.5635 - val_acc: 0.6805\n",
      "Epoch 126/1000\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.1155 - acc: 0.9574 - val_loss: 2.5319 - val_acc: 0.6790\n",
      "Epoch 127/1000\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.1160 - acc: 0.9569 - val_loss: 2.6191 - val_acc: 0.6777\n",
      "Epoch 128/1000\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.1055 - acc: 0.9621 - val_loss: 2.6846 - val_acc: 0.6758\n",
      "Epoch 129/1000\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.1172 - acc: 0.9561 - val_loss: 2.8442 - val_acc: 0.6553\n",
      "Epoch 130/1000\n",
      "50000/50000 [==============================] - 18s 359us/step - loss: 0.1220 - acc: 0.9548 - val_loss: 2.5835 - val_acc: 0.6798\n",
      "Epoch 131/1000\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 0.1176 - acc: 0.9573 - val_loss: 2.6988 - val_acc: 0.6644\n",
      "Epoch 132/1000\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 0.1157 - acc: 0.9571 - val_loss: 2.6930 - val_acc: 0.6715\n",
      "Epoch 133/1000\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.1076 - acc: 0.9600 - val_loss: 2.6144 - val_acc: 0.6821\n",
      "Epoch 134/1000\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 0.1030 - acc: 0.9622 - val_loss: 2.7207 - val_acc: 0.6739\n",
      "Epoch 135/1000\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 0.1134 - acc: 0.9573 - val_loss: 2.7367 - val_acc: 0.6649\n",
      "Epoch 136/1000\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.1234 - acc: 0.9552 - val_loss: 2.6440 - val_acc: 0.6787\n",
      "Epoch 137/1000\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 0.1015 - acc: 0.9627 - val_loss: 2.6069 - val_acc: 0.6844\n",
      "Epoch 138/1000\n",
      "45184/50000 [==========================>...] - ETA: 1s - loss: 0.1108 - acc: 0.9596"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
